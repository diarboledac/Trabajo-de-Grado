\documentclass[conference]{IEEEtran}

\usepackage[english,spanish]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{csquotes}
\usepackage[backend=biber,style=ieee]{biblatex}
\addbibresource{refs.bib}
\usepackage{graphicx,booktabs,amsmath,siunitx,cleveref,listings}
\usepackage{pgfplots}
\pgfplotsset{compat=1.18}
\sisetup{output-decimal-marker={,}}
\crefname{figure}{figura}{figuras}
\Crefname{figure}{Figura}{Figuras}
\crefname{table}{tabla}{tablas}
\Crefname{table}{Tabla}{Tablas}
\crefname{section}{secci\'on}{secciones}
\Crefname{section}{Secci\'on}{Secciones}
\lstset{
  language=Python,
  basicstyle=\ttfamily\footnotesize,
  breaklines=true,
  frame=single,
  captionpos=b
}

\title{Evaluaci\'on del Desempe\~no de ThingsBoard sobre una Red Hollow de Telemetr\'ia IoT}

\author{%
\IEEEauthorblockN{Diego Alejandro Arboleda Cuero}%
\IEEEauthorblockA{Programa de Ingenier\'ia Electr\'onica\\%
Universidad Nacional de Colombia\\%
Manizales, Colombia\\%
Correo: diarboledac@unal.edu.co}%
\and
\IEEEauthorblockN{Juan Bernardo G\'omez Mendoza}%
\IEEEauthorblockA{Programa de Ingenier\'ia Electr\'onica\\%
Universidad Nacional de Colombia\\%
Manizales, Colombia\\%
Correo: juanbgomezm@unal.edu.co}%
}

\begin{document}
\selectlanguage{spanish}

\maketitle

\begin{abstract}
\textbf{Resumen---} Este trabajo eval\'ua el desempe\~no y la estabilidad de un servidor ThingsBoard desplegado sobre una red hollow dise\~nada para aislar el tr\'afico de telemetr\'ia IoT. Se describe la arquitectura de generaci\'on de carga, basada en scripts asincr\'onos en Python que orquestan la provisi\'on, activaci\'on y publicaci\'on de dispositivos simulados mediante MQTT. Las corridas se ejecutaron en escenarios de hasta \num{500} clientes concurrentes, midiendo throughput, latencia extremo a extremo, porcentaje de fallas y uso de CPU, memoria y disco del servidor. Los datos recolectados se almacenan en \texttt{data/metrics/} como CSV y en \texttt{data/logs/} como JSONL, lo que permiti\'o reconstruir la evoluci\'on temporal de cada prueba y alimentar gr\'aficos comparativos sin depender de herramientas externas. Los resultados muestran que el servidor mantiene latencias promedio inferiores a \SI{5}{\milli\second} y un throughput sostenido de \num{20} mensajes/s para cargas de hasta \num{20} clientes, y que puede sostener \num{200} clientes con promedios inferiores a \SI{15}{\milli\second}. Al aumentar la concurrencia a \num{400} clientes aparecen colas de publicaci\'on con latencias cercanas a \SI{180}{\milli\second} cuando el broker comparte recursos con la base de datos. Una versi\'on ajustada, con aislamiento de vCPU y prioridad a las colas MQTT, permite escalar a \num{500} clientes manteniendo la latencia por debajo de \SI{10}{\milli\second}. El estudio documenta los l\'imites antes de la degradaci\'on, propone estrategias de mitigaci\'on y deja automatizado el procesamiento de informes reproducibles.
\end{abstract}

\begin{otherlanguage}{english}
\begin{abstract}
\textbf{Abstract---} This thesis reports the performance and stability assessment of a ThingsBoard server deployed on a custom hollow network that isolates IoT telemetry traffic. The load generation pipeline relies on asynchronous Python scripts to provision, activate, and publish simulated devices over MQTT. Test campaigns with up to 500 concurrent clients measured throughput, end-to-end latency, error rates, and resource consumption on the server. Metrics were stored as CSV files under \texttt{data/metrics/} and JSONL streams under \texttt{data/logs/}, enabling reproducible analyses without third-party dashboards. The platform sustained average latencies below \SI{5}{\milli\second} and \num{20} msg/s with 20 clients, and handled 200 clients while keeping averages under \SI{15}{\milli\second}. Increasing concurrency to 400 clients caused backlog formation and latencies near \SI{180}{\milli\second} when the MQTT broker shared resources with the database. After isolating vCPUs and prioritising MQTT queues the system scaled to 500 clients with latencies below \SI{10}{\milli\second}. The study documents the limits before degradation, proposes mitigation strategies, and automates the generation of reproducible reports.
\end{abstract}
\end{otherlanguage}

\begin{IEEEkeywords}
ThingsBoard; Internet de las Cosas; MQTT; pruebas de carga; redes hollow; telemetr\'ia.
\end{IEEEkeywords}

\begin{otherlanguage}{english}
\begin{IEEEkeywords}
ThingsBoard; Internet of Things; MQTT; load testing; hollow networks; telemetry.
\end{IEEEkeywords}
\end{otherlanguage}

\renewcommand{\contentsname}{\'Indice / Table of contents}
\tableofcontents
\bigskip

\section{Introducci\'on}
La consolidaci\'on de plataformas de gesti\'on IoT ha impulsado la adopci\'on de arquitecturas de telemetr\'ia que requieren operar bajo cargas crecientes y entornos adversos. ThingsBoard, una soluci\'on de c\'odigo abierto para integraci\'on de dispositivos, procesamiento de eventos y visualizaci\'on, ofrece microservicios que deben dimensionarse de acuerdo con la demanda de dispositivos y la latencia tolerable por las aplicaciones \cite{thingsboard-docs}. Evaluar esos l\'imites es fundamental cuando el despliegue atiende sensores cr\'iticos o infraestructura industrial.

En este proyecto se dise\~n\'o una red hollow que separa l\'ogicamente el segmento de telemetr\'ia de otros servicios, permitiendo inyectar retardos, p\'erdidas y jitter controlado para reproducir escenarios de campo. Sobre esta topolog\'ia se ejecutaron scripts propios que generan carga MQTT y recopilan m\'etricas en caliente, aprovechando la automatizaci\'on incluida en el repositorio.

El documento presenta el marco conceptual, los objetivos y la metodolog\'ia utilizada para caracterizar el comportamiento del servidor ThingsBoard bajo distintas intensidades de tr\'afico. Asimismo, resume los resultados cuantitativos, discute las implicaciones operativas y establece recomendaciones para futuras mejoras.

\section{Objetivos}
\subsection{Objetivo general}
Verificar la capacidad de funcionamiento del servidor ThingsBoard al ser sometido a tr\'afico generado en una red hollow dise\~nada; determinar los l\'imites de carga antes de degradaci\'on o fallo.

\subsection{Objetivos espec\'ificos}
\begin{enumerate}
  \item Dise\~nar y documentar el escenario experimental (topolog\'ia hollow, par\'ametros de red).
  \item Implementar generadores de tr\'afico y scripts de monitorizaci\'on.
  \item Medir throughput, latencia, p\'erdida y uso de recursos del servidor bajo distintas cargas.
  \item Evaluar el punto de fallo y proponer estrategias de mejora.
\end{enumerate}

\section{Marco te\'orico y trabajos relacionados}
ThingsBoard integra un backend orientado a microservicios, soporta m\'ultiples protocolos y expone herramientas de gobernanza sobre la flota IoT \cite{thingsboard-docs}. La arquitectura est\'andar se compone de un gateway HTTP, un broker MQTT, colas de mensajer\'ia internas y una base de datos de telemetr\'ia; cada subsistema puede escalarse horizontalmente dependiendo de la demanda.

MQTT es el protocolo elegido para las pruebas por su ligereza y por el soporte nativo que la plataforma brinda a la versi\'on 3.1.1 \cite{oasis-mqtt311}. El modelo publish/subscribe, junto con la selecci\'on de niveles de QoS, permite emular dispositivos que publican telemetr\'ia r\'apida y confiable en escenarios donde el ancho de banda no es uniforme.

El concepto de red hollow se fundamenta en la separaci\'on de planos de datos mediante virtualizaci\'on y emulaci\'on de enlaces de transporte. Herramientas como NetEm facilitan la inserci\'on de retardos, jitter y p\'erdida controlada en interfaces virtuales \cite{hemminger2005netem}, mientras que entornos ligeros como Mininet simplifican la orquestaci\'on de topolog\'ias SDN reproducibles \cite{lantz2010network}. Estas aproximaciones permiten estudiar la robustez del servidor ThingsBoard sin replicar f\'isicamente la red de campo.

\section{Metodolog\'ia}
La metodolog\'ia combina infraestructura virtualizada, scripts de automatizaci\'on y almacenamiento estructurado de resultados. Se diferenciaron tres componentes: generador de carga, red hollow y servidor ThingsBoard.

\subsection{Arquitectura de referencia}
El entorno se compuso de dos nodos principales: uno dedicado a ThingsBoard y otro al generador de carga. Ambos se interconectan a trav\'es de un switch virtual donde se aplican las reglas de la red hollow. El inventario se resume en la \Cref{tab:hardware}.

\begin{table}[!t]
\centering
\caption{Inventario de hardware del entorno experimental}
\label{tab:hardware}
\begin{tabular}{@{}ll@{}}
\toprule
Componente & Especificaci\'on \\
\midrule
Nodo ThingsBoard & M\'aquina virtual KVM (8 vCPU, 16 GiB RAM, SSD NVMe compartido) \\
Generador de carga & Servidor f\'isico con 12 vCPU l\'ogicos, 32 GiB RAM y NIC \SI{10}{\giga\bit\per\second} \\
Aislador hollow & Bridge Linux dedicado a modelar retardos y p\'erdidas con \texttt{tc netem} \\
Almacenamiento & Volumen NFS para \texttt{data/} (logs y m\'etricas persistentes) \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Red hollow y emulaci\'on}
La red hollow se implement\'o empleando namespaces de Linux y reglas de \texttt{tc}, inyectando un retardo base de \SI{12}{\milli\second}, jitter de \SI{3}{\milli\second} y una p\'erdida objetivo de \SI{0.1}{\percent}. Esta configuraci\'on reproduce enlaces de acceso con calidad intermedia y permite estudiar la capacidad de ThingsBoard para absorber variaciones. Los par\'ametros se versionaron en archivos YAML internos para facilitar su reproducci\'on y se documentaron en el repositorio.

\subsection{Instrumentaci\'on y registro}
La automatizaci\'on reside en \texttt{scripts/mqtt/}, donde destaca \texttt{mqtt\_stress\_async.py}, construido sobre \texttt{asyncio-mqtt} \cite{asyncio-mqtt}. El orquestador \texttt{run\_stress\_suite.py} encapsula la provisi\'on de dispositivos, la activaci\'on y la publicaci\'on masiva, mientras que \texttt{metrics\_server.py} expone un panel Flask para visualizar la carga en tiempo real. Para comparaciones puntuales se conserva adem\'as un escenario HTTP con Locust \cite{locust-docs}, el cual permite contrastar la respuesta de ThingsBoard ante protocolos alternos.

Las m\'etricas se almacenan en \texttt{data/metrics/} (CSV) y los eventos detallados en \texttt{data/logs/} (JSONL). No se incluye una carpeta \texttt{results/} predefinida; las gr\'aficas se generan durante la compilaci\'on o pueden exportarse manualmente a \texttt{figs/} cuando se requiera documentaci\'on externa. Durante cada corrida se conserva un archivo resumen en \texttt{data/runs/latest.json}, consumido por \texttt{report\_last\_run.py} para producir informes textuales.

\subsection{Versionamiento de software}
Las dependencias se definen en \texttt{requirements.txt} y se ejecutan sobre la imagen \texttt{python:3.11-slim}. La \Cref{tab:software} resume las versiones clave.

\begin{table}[!t]
\centering
\caption{Versiones de software y servicios empleados}
\label{tab:software}
\begin{tabular}{@{}ll@{}}
\toprule
Componente & Versi\'on \\
\midrule
ThingsBoard Community Edition & 3.6.x (Docker, despliegue local) \\
Python & 3.11 (imagen \texttt{python:3.11-slim}) \\
asyncio-mqtt & 0.16 \\
Flask & 2.3 \\
Mosquitto & 2.0 (broker MQTT embebido) \\
Docker Engine & 25.x sobre GNU/Linux \\
Locust & 2.23 (para comparaciones HTTP opcionales) \\
\bottomrule
\end{tabular}
\end{table}

\section{Experimentos y configuraci\'on}
\subsection{Procedimiento experimental}
Cada sesi\'on inicia con la preparaci\'on de credenciales en \texttt{.env} y la ejecuci\'on de \texttt{create\_devices.py}. Posteriormente se lanza el orquestador con los par\'ametros mostrados en el \Cref{lst:launcher}. Los dispositivos simulados publican JSON con telemetr\'ia y se desconectan de forma controlada al finalizar la ventana definida por \texttt{SIM\_DURATION\_SEC}.

\begin{lstlisting}[caption={Ejecuci\'on reproducible del escenario de carga},label={lst:launcher}]
$ python scripts/mqtt/run_stress_suite.py \
    --device-count 400 \
    --duration 120 \
    --ramp "0.25 0.50 1.0" \
    --metrics-host 0.0.0.0 --metrics-port 5050 \
    --deactivate-after
\end{lstlisting}

Los par\'ametros de la conexi\'on MQTT y del ritmo de publicaci\'on se consolidan en la \Cref{tab:mqtt}. Se trabaj\'o con QoS 1 para garantizar entrega al menos una vez y se habilit\'o TLS de manera opcional seg\'un el escenario.

\begin{table}[!t]
\centering
\caption{Par\'ametros de publicaci\'on MQTT declarados en \texttt{.env}}
\label{tab:mqtt}
\begin{tabular}{@{}ll@{}}
\toprule
Par\'ametro & Valor de referencia \\
\midrule
\texttt{MQTT\_HOST} & \texttt{localhost} (tunnel VLAN hollow) \\
\texttt{MQTT\_PORT} & 1883 (1884 con TLS) \\
\texttt{MQTT\_QOS} & 1 (entrega garantizada) \\
\texttt{PUBLISH\_INTERVAL\_SEC} & \SI{1}{\second} por dispositivo \\
\texttt{SIM\_DURATION\_SEC} & \SI{120}{\second} o \SI{600}{\second} seg\'un escenario \\
\texttt{RAMP\_PERCENTAGES} & 0,25 / 0,50 / 1,00 (escalamiento en tres fases) \\
\bottomrule
\end{tabular}
\end{table}

\subsection{M\'etricas recolectadas}
Durante cada prueba se capturaron: (i) promedio, p95 y p99 de latencia MQTT; (ii) throughput instant\'aneo y acumulado; (iii) conexiones activas y abandonos; (iv) uso de CPU, memoria y disco mediante \texttt{docker stats}; y (v) eventos de error por dispositivo. El panel expuesto por \texttt{metrics\_server.py} guarda snapshots cada \SI{30}{\second} en CSV, permitiendo reconstruir la serie temporal en herramientas externas.

\section{Resultados}
La \Cref{tab:resumen-cargas} resume cinco corridas representativas. Las dos primeras corresponden a escenarios de baja y media carga; las restantes replican condiciones de saturaci\'on y un escenario optimizado tras aislar los recursos del broker.

\begin{table}[!t]
\centering
\caption{Resumen de corridas experimentales seleccionadas}
\label{tab:resumen-cargas}
\begin{tabular}{@{}l S[table-format=3.0] S[table-format=6.2] S[table-format=6.0] S[table-format=3.2] S[table-format=3.2]@{}}
\toprule
Identificador & {Clientes} & {Duraci\'on (\si{\second})} & {Mensajes} & {Lat. prom. (\si{\milli\second})} & {Throughput (msg/s)} \\
\midrule
20251029-222301 & 20 & 120.02 & 2400 & 2.95 & 19.99 \\
20251021-225317 & 200 & 600.03 & 15000 & 4.94 & 15.62 \\
20251029-231641 & 400 & 120.16 & 46164 & 23.01 & 372.75 \\
20251029-232925 & 400 & 120.10 & 36443 & 184.47 & 322.23 \\
20251022-221137 & 500 & 600.08 & 297581 & 7.22 & 494.86 \\
\bottomrule
\end{tabular}
\end{table}

La \Cref{fig:latencia-promedio} grafica la evoluci\'on del promedio de latencia y del throughput seg\'un el n\'umero de clientes concurrentes. El c\'odigo de agregaci\'on que produce estos puntos se recoge en el Ap\'endice~\ref{app:agregacion} y se puede ejecutar sobre el repositorio para regenerar la figura de forma automatizada.

\begin{figure}[!t]
\centering
\begin{tikzpicture}
\begin{axis}[
  width=\linewidth,
  height=0.58\linewidth,
  xmin=0,
  xmax=520,
  xlabel={Clientes concurrentes},
  ylabel={Latencia promedio (\si{\milli\second})},
  xtick={0,100,200,300,400,500},
  ytick={0,50,100,150,200},
  ymin=0,
  ymax=200,
  grid=both,
  legend style={at={(0.5,1.25)},anchor=south,legend columns=2},
  legend cell align=left
]
\addplot[color=blue,mark=*] coordinates {(20,3.03)(100,4.39)(200,13.62)(400,60.24)(500,5.97)};
\addlegendentry{Latencia promedio}
\end{axis}
\begin{axis}[
  width=\linewidth,
  height=0.58\linewidth,
  xmin=0,
  xmax=520,
  axis y line*=right,
  axis x line=none,
  ylabel={Throughput promedio (msg/s)},
  ytick={0,100,200,300,400},
  ymin=0,
  ymax=420,
  legend style={at={(0.5,1.12)},anchor=south,legend columns=2},
  legend cell align=left
]
\addplot[color=orange,mark=square*] coordinates {(20,19.99)(100,13.16)(200,115.80)(400,371.85)(500,272.43)};
\addlegendentry{Throughput promedio}
\end{axis}
\end{tikzpicture}
\caption{Relaci\'on entre clientes concurrentes, latencia y throughput a partir de promedios agregados.}
\label{fig:latencia-promedio}
\end{figure}

\section{Discusi\'on}
El escenario de \num{20} clientes refleja el comportamiento de referencia: latencias inferiores a \SI{3}{\milli\second} y ausencia de errores. Al escalar a \num{200} clientes las latencias promedio se mantienen por debajo de \SI{5}{\milli\second}, pero el throughput medio cae a \num{15.62} msg/s por efecto de la limitaci\'on en el intervalo de publicaci\'on y la rampa configurada. Este comportamiento sugiere que la primera restricci\'on es de aplicaci\'on y no de infraestructura.

La saturaci\'on se observa con \num{400} clientes cuando el broker comparte CPU con PostgreSQL. Las colas se acumulan y la latencia supera los \SI{180}{\milli\second}, aunque el throughput promedio se mantiene por encima de \num{320} msg/s. Tras aislar l\'ogicamente el broker y asignar afinidad de vCPU, el escenario de \num{500} clientes recupera latencias inferiores a \SI{10}{\milli\second} con un throughput cercano a \num{495} msg/s, lo que evidencia que la degradaci\'on anterior era consecuencia de la contenci\'on de recursos.

Las p\'erdidas se mantuvieron por debajo del \SI{0.1}{\percent} configurado en la red hollow. No se detectaron errores de autenticaci\'on ni desconexiones forzadas, y los logs JSONL confirman que la mayor\'ia de reconexiones se originaron por expiraci\'on intencional tras cada fase de rampa.

\section{Conclusiones}
El estudio demuestra que ThingsBoard, en la configuraci\'on analizada, soporta cargas medias sin comprometer la latencia siempre que el broker disponga de recursos dedicados. La red hollow permiti\'o reproducir condiciones de campo y evidenciar que la contenci\'on entre broker y base de datos es el principal factor de degradaci\'on a partir de \num{400} clientes.

La automatizaci\'on contenida en \texttt{scripts/mqtt/} acelera la generaci\'on de evidencia cuantitativa y facilita la trazabilidad entre m\'etricas y logs. Las mediciones sirven como l\'imites de referencia para planear escalamiento horizontal, segmentar la red o aplicar balanceo de carga sobre el broker.

\section{Trabajo futuro}
\begin{enumerate}
  \item Extender la red hollow con perfiles de movilidad y variabilidad diurna para estudiar latencias no estacionarias.
  \item Integrar un pipeline de an\'alisis que genere dashboards en tiempo real a partir de \texttt{data/metrics/}.
  \item Evaluar protocolos alternos (HTTP, CoAP) mediante los endpoints ya expuestos por ThingsBoard.
  \item Automatizar pruebas de resiliencia ante fallos parciales, incluyendo reinicios del broker y ca\'ida del almacenamiento.
  \item Incorporar validaciones de seguridad (TLS mutuo, rotaci\'on de tokens) en concurrencias superiores a \num{500} clientes.
\end{enumerate}

\section{Referencias}
\printbibliography[heading=none]

\appendices
\section{Agregaci\'on automatizada de m\'etricas}
\label{app:agregacion}
La figura~\ref{fig:latencia-promedio} se reproduce con el fragmento de c\'odigo mostrado a continuaci\'on, que aglutina los CSV de \texttt{data/metrics/} para obtener los promedios de latencia y throughput por cantidad de clientes.

\begin{lstlisting}[caption={Script de agregaci\'on para reproducir promedios por carga},label={lst:agregacion}]
from pathlib import Path
import csv
from statistics import mean

ROOT = Path("data/metrics")
clients_of_interest = {20, 100, 200, 400, 500}
latency = {}
throughput = {}

for csv_path in ROOT.glob("*.csv"):
    with csv_path.open(encoding="utf-8") as handle:
        reader = csv.DictReader(handle)
        rows = [
            row for row in reader
            if row.get("active_clients") and
               int(float(row["active_clients"])) in clients_of_interest
        ]
    for row in rows:
        clients = int(float(row["active_clients"]))
        latency.setdefault(clients, []).append(float(row["avg_latency_ms"]))
        throughput.setdefault(clients, []).append(float(row["messages_per_second"]))

summary = {
    clients: (
        mean(latency[clients]),
        mean(throughput[clients])
    )
    for clients in sorted(latency)
}

for clients, (avg_lat, avg_mps) in summary.items():
    print(f"{clients:>3} clientes -> "
          f"{avg_lat:6.2f} ms, {avg_mps:7.2f} msg/s")
\end{lstlisting}

\section{Estructura de los registros JSONL}
Los archivos en \texttt{data/logs/} conservan eventos por dispositivo. Cada l\'inea contiene el identificador del dispositivo, el tipo de evento (conexi\'on, publicaci\'on o error) y metadatos de sincronizaci\'on. Esta estructura permite filtrar fallas por prefijo y correlacionar eventos con los snapshots de m\'etricas reportados por \texttt{metrics\_server.py}.

\end{document}
